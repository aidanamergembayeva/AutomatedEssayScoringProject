{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "354ec7c8-914d-476f-ac1e-26ee80b72933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from skopt import BayesSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c52bbfb-be85-463d-94d2-e9ccfe5dd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    \"\"\"Calculate Quadratic Weighted Kappa.\"\"\"\n",
    "    y_true = np.round(y_true).astype(int)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0678e85a-2256-4fd8-81d9-0ae6ffd2d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path, sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "38eabbde-8230-4e8b-b2aa-2c2ec3908c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(data):\n",
    "    \"\"\"Preprocess text data.\"\"\"\n",
    "    data['essay'] = data['essay'].astype(str).str.strip() \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "78a57aa8-98b1-4d34-871f-6b953cb5990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_essays(texts, tokenizer, max_length=512):\n",
    "    \"\"\"Tokenize essays using BERT tokenizer.\"\"\"\n",
    "    print(\"Starting tokenization...\")\n",
    "    encodings = tokenizer(\n",
    "        texts.tolist(),\n",
    "        max_length=max_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    print(\"Tokenization completed.\")\n",
    "    print(f\"Sample input_ids: {encodings['input_ids'][0]}\")\n",
    "    print(f\"Sample attention_mask: {encodings['attention_mask'][0]}\")\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc3900eb-8bd4-4c5c-9822-0f2c4cddf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bert_lstm_model(learning_rate=1e-4, lstm_units=128, dropout_rate=0.3):\n",
    "    \"\"\"Build a BERT + LSTM model.\"\"\"\n",
    "    # Load pre-trained BERT model\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    for layer in bert_model.layers:\n",
    "        layer.trainable = False  # Freeze BERT layers for efficiency\n",
    "\n",
    "    # Input layers\n",
    "    input_ids = Input(shape=(512,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(512,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "    # BERT embeddings\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "\n",
    "    # LSTM layer\n",
    "    lstm_output = LSTM(lstm_units, return_sequences=False)(bert_output)\n",
    "\n",
    "    # Dense regression head\n",
    "    dropout = Dropout(dropout_rate)(lstm_output)\n",
    "    output = Dense(1, activation='linear')(dropout)\n",
    "\n",
    "    # Model definition\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ec691628-4b14-470b-a805-d09311ec8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(X, y, tokenizer):\n",
    "    \"\"\"Perform hyperparameter tuning using Bayesian Optimization.\"\"\"\n",
    "    def model_fn(learning_rate, lstm_units, dropout_rate):\n",
    "        return build_bert_lstm_model(\n",
    "            learning_rate=learning_rate,\n",
    "            lstm_units=int(lstm_units),\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "    model = KerasRegressor(build_fn=model_fn, verbose=0)\n",
    "\n",
    "    # Hyperparameter search space\n",
    "    search_space = {\n",
    "        'learning_rate': (1e-5, 1e-3, 'log-uniform'),\n",
    "        'lstm_units': (64, 256),\n",
    "        'dropout_rate': (0.2, 0.5),\n",
    "        'batch_size': (8, 16),\n",
    "        'epochs': (3, 10)\n",
    "    }\n",
    "\n",
    "    # Bayesian optimization\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=10,\n",
    "        cv=2,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit and find the best hyperparameters\n",
    "    bayes_search_result = bayes_search.fit(X, y)\n",
    "\n",
    "    print(f\"Best parameters: {bayes_search_result.best_params_}\")\n",
    "    print(f\"Best MSE: {-bayes_search_result.best_score_}\")\n",
    "\n",
    "    return bayes_search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "15451348-9bfa-4d77-b146-1e88f34f6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation loss.\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a2909ef-1634-435d-b66a-64b6bdd699a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/training_set_rel3.tsv' \n",
    "data = load_data(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77fecaa7-b40c-4d25-a4d8-02564c152bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f4874-11f1-42b4-8a5a-bf46a66230f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tokenization...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "encodings = tokenize_essays(data['essay'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941b2fc-c4be-4b13-9141-2fe632c97975",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {'input_ids': encodings['input_ids'], 'attention_mask': encodings['attention_mask']}\n",
    "y = data['domain1_score'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ee337-ffd3-4492-827f-8f28576fc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b268787-9c53-426f-8af0-dbb228c2c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = hyperparameter_tuning(X_train, y_train, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36229f7-9655-4e10-99d9-305cfdf2d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = build_bert_lstm_model(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    lstm_units=best_params['lstm_units'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429dad4-3e10-40a6-a575-52b74d1ed1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = final_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    epochs=best_params['epochs'],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ed1b7-297e-4aef-b5a9-3c974fd1a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save('models/bert_lstm_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf6ef0-2096-413e-8b0a-89f1c49bc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85511d6-e937-414b-9e63-63a439b94ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "spearman_corr, _ = spearmanr(y_test, y_pred)\n",
    "pearson_corr, _ = pearsonr(y_test, y_pred)\n",
    "qwk = quadratic_weighted_kappa(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc2796-5dd8-45e7-a761-a0cc6b193558",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.2f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.2f}\")\n",
    "print(f\"Quadratic Weighted Kappa: {qwk:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc287f92-a0ed-4eee-b13a-8cb6f95e7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a37a2-4900-44cd-944b-ece5c003c7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
